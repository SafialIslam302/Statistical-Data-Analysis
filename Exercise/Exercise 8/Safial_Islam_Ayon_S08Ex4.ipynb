{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we read in the data X and Y and transform it a bit. Since we also have a $\\beta_0$ that works as intercept, we need to add a column with 1's to the matrix $X$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X.txt', 'r') as handle:\n",
    "    X = handle.readlines()\n",
    "X = [i.split('\\n')[0] for i in X]\n",
    "X = [i.split(',') for i in X]\n",
    "# the following could prob. be done differently, \n",
    "# but i thought it was easier that way\n",
    "X_df = pd.DataFrame(X)\n",
    "X_df[0] = X_df[0].astype(float)\n",
    "X_df[1] = X_df[1].astype(float)\n",
    "X_df[2] = X_df[2].astype(float)\n",
    "X_df = X_df.rename(columns = {0:'X1', 1:'X2', 2:'X3'})\n",
    "# addition of the interception beta_0, as a column of 1 in the Matrix X\n",
    "X_df['X0'] = 1\n",
    "# reordering, to have the intercept as first column\n",
    "X_df = X_df[['X0', 'X1', 'X2', 'X3' ]]\n",
    "X = X_df.values\n",
    "\n",
    "with open('Y.txt', 'r') as handle:\n",
    "    Y = handle.readlines()\n",
    "Y = [i.split('\\n')[0] for i in Y]\n",
    "Y = [float(i) for i in Y]\n",
    "Y_df = pd.DataFrame(Y)\n",
    "Y_df = Y_df.rename(columns = {0:'Y'})\n",
    "Y = Y_df.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate $\\hat{\\beta} = (X^TX)^{-1}X^Ty$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00800698]\n",
      " [ 0.88161162]\n",
      " [-2.45938171]\n",
      " [-0.97715699]]\n"
     ]
    }
   ],
   "source": [
    "beta_hat = np.dot(np.linalg.inv(np.dot(X.T , X)) , np.dot(X.T , Y))\n",
    "print(beta_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our calculated $\\beta$ values are:\n",
    "\n",
    "$\\hat{\\beta_0} = -0.00800698$ , $\\hat{\\beta_1} = 0.88161162$ , $\\hat{\\beta_2} = -2.45938171$ , $\\hat{\\beta_3} = -0.97715699$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having these estimators, we can have a look at the observations (X1, Y), (X2, Y), (X3, Y) and get a sense of wether these linear coefficients give a good fit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation of $\\widehat{\\sigma^2}$ using $\\widehat{\\beta}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to estimate $\\widehat{\\sigma^2}$ using $\\widehat{\\beta}$, which we calculated in the lectures as \n",
    "$\\begin{align}\n",
    "    \\sigma^2 &= \\frac{1}{n} \\epsilon^T \\epsilon \\\\\n",
    "    \\sigma^2_{ad} &= \\frac{1}{n-p-1} \\epsilon^T \\epsilon \n",
    "\\end{align}$\n",
    "For the residuals $\\epsilon$, we have $\\epsilon = y - X\\hat{\\beta}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = Y - np.dot(X, beta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.95484056]]\n"
     ]
    }
   ],
   "source": [
    "n = 201 # or n = len(Y)\n",
    "sigma_sq_hat = 1/n * np.dot(residuals.T, residuals)\n",
    "print(sigma_sq_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the we have $\\widehat{\\sigma^2} = 0.95484056$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.97422819]]\n"
     ]
    }
   ],
   "source": [
    "p = 3\n",
    "sigma_sq_hat_adj = 1/(n - p - 1) * np.dot(residuals.T, residuals)\n",
    "print(sigma_sq_hat_adj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and $\\widehat{\\sigma^2}_{ad} = 0.97422819$.\n",
    "\n",
    "Here we can also see, that the estimator $\\widehat{\\sigma^2}$ underestimates the true value of $\\sigma^2$ and that the adjusted estimator $\\widehat{\\sigma^2_{ad}}$  is larger and also closer to the true value of $\\sigma^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8 Problem 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the Ridge regression, using the same data set and comparing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate $\\hat{\\beta} = (X^TX + \\lambda I_p)^{-1}X^Ty$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression:\n",
      "[-0.00800698  0.88161162 -2.45938171 -0.97715699]\n",
      "Ridge regression:\n",
      "lambda: 1\n",
      "estimates betas: \n",
      "[-0.00661661  0.87170097 -2.43608212 -0.97613668]\n",
      "lambda: 5\n",
      "estimates betas: \n",
      "[-1.43268680e-03  8.34103365e-01 -2.34715043e+00 -9.72158696e-01]\n",
      "lambda: 20\n",
      "estimates betas: \n",
      "[ 0.01363349  0.71705655 -2.06465393 -0.95846534]\n",
      "lambda: 100\n",
      "estimates betas: \n",
      "[ 0.0413792   0.402319   -1.25834761 -0.90237817]\n",
      "lambda: 500\n",
      "estimates betas: \n",
      "[ 0.03165688  0.10999069 -0.42691886 -0.7275989 ]\n"
     ]
    }
   ],
   "source": [
    "beta_hat_ridge = {\n",
    "    1: np.nan,\n",
    "    5: np.nan,\n",
    "    20: np.nan,\n",
    "    100: np.nan,\n",
    "    500: np.nan\n",
    "}\n",
    "lambda_mapping = {\n",
    "    1: 0,\n",
    "    5: 1,\n",
    "    20: 2,\n",
    "    100: 3,\n",
    "    500: 4\n",
    "}\n",
    "for l in beta_hat_ridge.keys():\n",
    "    beta_hat_ridge[l] = np.dot(np.linalg.inv(np.dot(X.T , X) + np.dot(l,np.identity(p+1))) , np.dot(X.T , Y))\n",
    "print('Linear regression:')\n",
    "print(beta_hat.flatten())\n",
    "\n",
    "print('Ridge regression:')\n",
    "for k,v in beta_hat_ridge.items():\n",
    "    print(f'lambda: {k}')\n",
    "    print(f'estimates betas: ')\n",
    "    print(v.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard linear regression:\n",
      "[[0.95484056]]\n",
      "[[0.97422819]]\n",
      "Ridge regression: lambda = 1\n",
      "sigma squared: [[0.95517093]]\n",
      "adjusted sigma squared: [[0.97456526]]\n",
      "Ridge regression: lambda = 5\n",
      "sigma squared: [[0.96250024]]\n",
      "adjusted sigma squared: [[0.98204339]]\n",
      "Ridge regression: lambda = 20\n",
      "sigma squared: [[1.04942681]]\n",
      "adjusted sigma squared: [[1.07073497]]\n",
      "Ridge regression: lambda = 100\n",
      "sigma squared: [[1.83522968]]\n",
      "adjusted sigma squared: [[1.87249322]]\n",
      "Ridge regression: lambda = 500\n",
      "sigma squared: [[3.77297588]]\n",
      "adjusted sigma squared: [[3.84958453]]\n"
     ]
    }
   ],
   "source": [
    "residuals = Y - np.dot(X, beta_hat)\n",
    "n = 201 # or n = len(Y)\n",
    "sigma_sq_hat = 1/n * np.dot(residuals.T, residuals)\n",
    "p = 3\n",
    "sigma_sq_hat_adj = 1/(n - p - 1) * np.dot(residuals.T, residuals)\n",
    "print('Standard linear regression:')\n",
    "print(sigma_sq_hat)\n",
    "print(sigma_sq_hat_adj)\n",
    "for l in beta_hat_ridge.keys():\n",
    "    print(f'Ridge regression: lambda = {l}')\n",
    "    residuals = Y - np.dot(X, beta_hat_ridge[l])\n",
    "    n = 201 # or n = len(Y)\n",
    "    sigma_sq_hat = 1/n * np.dot(residuals.T, residuals)\n",
    "    p = 3\n",
    "    sigma_sq_hat_adj = 1/(n - p - 1) * np.dot(residuals.T, residuals)\n",
    "    print(f'sigma squared: {sigma_sq_hat}')\n",
    "    print(f'adjusted sigma squared: {sigma_sq_hat_adj}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "39ac581219574b4335d62c2e9b2cff9f90f4196085ffba151b998aae042de897"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
